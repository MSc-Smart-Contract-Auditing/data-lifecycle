{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-9lyakvfe/unsloth_fbd538a7fda1458796bccd2bae7da3fd\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-9lyakvfe/unsloth_fbd538a7fda1458796bccd2bae7da3fd\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 8d9bd0ea8bf662618ba96fe7fe3478c5b81d0dff\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tyro in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.3)\n",
      "Requirement already satisfied: transformers>=4.38.2 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.41.0.dev0)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.0)\n",
      "Requirement already satisfied: sentencepiece in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.2)\n",
      "Requirement already satisfied: psutil in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.8)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
      "Requirement already satisfied: numpy in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: filelock in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.22.2)\n",
      "Requirement already satisfied: packaging in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from transformers>=4.38.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.4.16)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from transformers>=4.38.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from transformers>=4.38.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.9.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.17.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Requirement already satisfied: xformers in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (0.0.25.post1)\n",
      "Requirement already satisfied: trl in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (0.8.6)\n",
      "Requirement already satisfied: peft in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (0.10.1.dev0)\n",
      "Requirement already satisfied: accelerate in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (0.30.0.dev0)\n",
      "Requirement already satisfied: bitsandbytes in /vol/bitbucket/kza23/msc/lib/python3.10/site-packages (0.43.1)\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# # major_version, minor_version = torch.cuda.get_device_capability()\n",
    "# # print(major_version)\n",
    "# # Must install separately since Colab has torch 2.2.1, which breaks packages\n",
    "# !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "# # if major_version >= 8:\n",
    "# #     # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n",
    "# #     !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
    "# # else:\n",
    "# #     # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n",
    "# !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "# # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth: Fast Llama patching release 2024.5\n",
      "   \\\\   /|    GPU: NVIDIA A30 MIG 2g.12gb. Max memory: 11.688 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "max_seq_length = 20 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vulnerable = load_dataset(\n",
    "  \"msc-smart-contract-audition/vulnerable-functions-base\",\n",
    "  split='train',\n",
    "  escapechar='\\\\',\n",
    ")\n",
    "\n",
    "dataset_verified = load_dataset(\n",
    "  \"msc-smart-contract-audition/vulnerable-functions-base\",\n",
    "  name=\"verified-functions\",\n",
    "  split='train',\n",
    "  escapechar='\\\\',\n",
    ")\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_vulnerable = dataset_vulnerable.to_pandas()\n",
    "df_verified = dataset_verified.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Given the below vulnerability description, provide a single vulnerability type which can be defined by multiple words.\n",
    "It needs describes the vulnerability as accurate as possible while avoiding specifcs like contract names, function names, variable names, etc.\n",
    "Do not explain the reason for your choice, or provide any additional context about the vulnerability itself (this includes notes, why you chose so). Do not add any text or characters like quotations<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Vulnerability Description:\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Vulnerability type:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label extraction\n",
    "Multiple prompting approaches were tried:\n",
    "1. Initially the model was prompted to extract a label that directly could be used for classification using the description. However, it turns out that too much of the task gets outsourced to the model and it struggles to produce nice classes which would encapsulate all the vulnarabilities. The model essentially was tasked to provide a class for a vulnerability of unknown set of vulnerability types. It is a very tricky task without any knowledge of all other vulnerabilities. For instance these are two examples of what the model produced for two audits: \"Insufficient input validation\" and \"Unvalidated input\" \"Unvalidated User-Input\". These are three separate instances and if the model had the knowledge about them prior to classfiying each one it would have classified all 3 the same (e.g. \"Insufficient Validation\"), which is the desirable result for classification labels.\n",
    "\n",
    "2. Instead of forcing the model to predict a general label with no context of other labels (i.e. without knowledge how general it has to be), the model was tasked to output a much more specific type without adhereing to generality or homogenity of labels. The only condition that the model was imposed with was to not include any specifics about the vulnerability e.g. function names, contract names, specific variable names, etc. Afterwards using unsupervised approaches the labels are able to be extracted just based on these types. This time all the vulnerabilities would be present and in addition would be clustered. The tasks transforms into providing a general label based on the cluster of labels instead of making up general labels. This is a much more tractable task as it only involves reasoning on the data provided in the prompt itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = df_vulnerable['description'].apply(lambda x: query_template.format(x.replace(\"\\\\n\", \"\\n\")))\n",
    "queries = queries.drop(queries.index[534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for idx, query in enumerate(queries):\n",
    "#     if len(tokenizer(query)[\"input_ids\"]) > 8000:\n",
    "#         print(\"Query too long!\")\n",
    "#         print(idx, query)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_query = \"\"\"\n",
    "# <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "# Given the below vulnerability audit, provide a single vulnerability type which can be defined by multiple words.\n",
    "# The type needs to describe the vulnerability as accurately as possible without including any specifics about the contract, function and variable names.\n",
    "# Do not provide any explanations or write any notes for your decision.\n",
    "# Output the result in the following format:\n",
    "# \"Vulnerability type: type\"\n",
    "# Do not add any additional text or characters.<|eot_id|>\n",
    "# <|start_header_id|>user<|end_header_id|>\n",
    "# Audit title:\n",
    "# An attacker can increase liquidity to the position's UniswapNFT to prevent the position from being closed\n",
    "# Audit body:\n",
    "# UniswapV3NPM allows the user to increase liquidity to any NFT.\n",
    "# When closing a position, in `_redeemPosition()`, only the initial liquidity of the NFT will be decreased, and then the NFT will be burned.\n",
    "# If the liquidity of the NFT is not 0, burning will fail.\n",
    "# This allows an attacker to add 1 wei liquidity to the position's NFT to prevent the position from being closed, and later when the position expires, the attacker can liquidate it.<|eot_id|>\n",
    "# <|start_header_id|>assistant<|end_header_id|>\n",
    "# Vulnerability type:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/1971 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m tqdm(queries):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# for query in queries[:20]:\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     output_tokens \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_new_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[1;32m      7\u001b[0m     decoded_output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_tokens[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:800\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 800\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    802\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:800\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 800\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    802\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "classes = []\n",
    "for query in tqdm(queries):\n",
    "# for query in queries[:20]:\n",
    "    inputs = tokenizer(query, return_tensors = \"pt\", truncation=True).to(\"cuda\")\n",
    "    output_tokens = model.generate(**inputs, max_new_tokens = 32, pad_token_id=tokenizer.pad_token_id)\n",
    "    decoded_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True, pad_token_id=tokenizer.pad_token_id)\n",
    "    classes.append(decoded_output.split(\"Vulnerability type:\\n\")[1].strip().lower())\n",
    "    # print(decoded_output.split(\"Vulnerability type:\\n\")[1].strip())\n",
    "df = pd.DataFrame(classes, columns=['type'])\n",
    "df.to_csv(\"vulnerability_types.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below vulnerability audit contains a description of a vulnerability contained in the code blocks.\n",
    "All the text needs to be extracted removing just the codeblocks. The inline code should be kept as is. The text needs to remain the same but you may fix any typos or grammatical errors.<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Vulnerability audit:\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Vulnerability text:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = df_vulnerable['description'].apply(lambda x: query_template.format(x.replace(\"\\\\n\", \"\\n\")))\n",
    "queries = queries.drop(queries.index[534]) # Drop this row as it exceeds the 8000 token limit (it has a whole contract in the description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_params = {\n",
    "    'quoting': csv.QUOTE_MINIMAL,  # quoting\n",
    "    'quotechar': '\"',  # quotechar\n",
    "    'escapechar': '\\\\',  # escapechar\n",
    "    'doublequote': False,  # Ensure doublequote is set to False as you are using escapechar\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                    | 230/1971 [34:43<4:22:54,  9.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m tqdm(queries):\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# for idx, query in enumerate(queries[:1]):\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(query, return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     output_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     decoded_output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_tokens[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[1;32m      8\u001b[0m     classes\u001b[38;5;241m.\u001b[39mappend(decoded_output\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVulnerability text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/unsloth/models/llama.py:987\u001b[0m, in \u001b[0;36m_wrap_fast_inference.<locals>._fast_generate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# Autocasted\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m device_type, dtype \u001b[38;5;241m=\u001b[39m dtype):\n\u001b[0;32m--> 987\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# Unset a flag for generation!\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/transformers/generation/utils.py:1610\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assisted_decoding(\n\u001b[1;32m   1594\u001b[0m         input_ids,\n\u001b[1;32m   1595\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1607\u001b[0m     )\n\u001b[1;32m   1608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1609\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1610\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/transformers/generation/utils.py:2524\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2524\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2527\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2529\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2532\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/unsloth/models/llama.py:795\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_CausalLM_fast_forward\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    792\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqwen2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 795\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    803\u001b[0m         causal_mask \u001b[38;5;241m=\u001b[39m xformers\u001b[38;5;241m.\u001b[39mattn_bias\u001b[38;5;241m.\u001b[39mLowerTriangularMask()\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/unsloth/models/llama.py:749\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward_inference\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    747\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    748\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m fast_rms_layernorm_inference(decoder_layer\u001b[38;5;241m.\u001b[39minput_layernorm, hidden_states)\n\u001b[0;32m--> 749\u001b[0m hidden_states, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaAttention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaged_attention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual\n\u001b[1;32m    759\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/unsloth/models/llama.py:154\u001b[0m, in \u001b[0;36mLlamaAttention_fast_forward_inference\u001b[0;34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[0m\n\u001b[1;32m    152\u001b[0m Qn \u001b[38;5;241m=\u001b[39m fast_linear_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj, Xn, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_QA[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    153\u001b[0m Kn \u001b[38;5;241m=\u001b[39m fast_linear_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj, Xn, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_KV[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 154\u001b[0m Vn \u001b[38;5;241m=\u001b[39m \u001b[43mfast_linear_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_proj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp_KV\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m Qn \u001b[38;5;241m=\u001b[39m Qn\u001b[38;5;241m.\u001b[39mview(bsz, \u001b[38;5;241m1\u001b[39m, n_heads,    head_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    156\u001b[0m Kn \u001b[38;5;241m=\u001b[39m Kn\u001b[38;5;241m.\u001b[39mview(bsz, \u001b[38;5;241m1\u001b[39m, n_kv_heads, head_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/unsloth/kernels/utils.py:210\u001b[0m, in \u001b[0;36mfast_linear_forward\u001b[0;34m(proj, X, temp_lora, out)\u001b[0m\n\u001b[1;32m    208\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(X, W\u001b[38;5;241m.\u001b[39mt(), out \u001b[38;5;241m=\u001b[39m out)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m bsz \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_len \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 210\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfast_gemv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     W \u001b[38;5;241m=\u001b[39m fast_dequantize(W\u001b[38;5;241m.\u001b[39mt(), W_quant)\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/unsloth/kernels/utils.py:194\u001b[0m, in \u001b[0;36mfast_gemv\u001b[0;34m(X, W, quant_state, out)\u001b[0m\n\u001b[1;32m    190\u001b[0m fx \u001b[38;5;241m=\u001b[39m cgemm_4bit_inference_naive_fp16 \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[1;32m    191\u001b[0m     cgemm_4bit_inference_naive_bf16\n\u001b[1;32m    193\u001b[0m blocksize \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int32(blocksize)\n\u001b[0;32m--> 194\u001b[0m fx(m, n, k, get_ptr(X), \u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m, get_ptr(absmax), get_ptr(stats), get_ptr(out),\n\u001b[1;32m    195\u001b[0m    lda, ldb, ldc, blocksize)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/bitsandbytes/functional.py:454\u001b[0m, in \u001b[0;36mget_ptr\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ct\u001b[38;5;241m.\u001b[39mc_void_p(\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "classes = []\n",
    "for query in tqdm(queries):\n",
    "# for idx, query in enumerate(queries[:1]):\n",
    "    inputs = tokenizer(query, return_tensors = \"pt\", truncation=True).to(\"cuda\")\n",
    "    output_tokens = model.generate(**inputs, max_new_tokens = 512, pad_token_id=tokenizer.pad_token_id)\n",
    "    decoded_output = tokenizer.decode(output_tokens[0], skip_special_tokens=True, pad_token_id=tokenizer.pad_token_id)\n",
    "    classes.append(decoded_output.split(\"Vulnerability text:\\n\")[1].strip().replace(\"\\n\", \"\\\\n\"))\n",
    "    # print(decoded_output.split(\"Vulnerability text:\\n\")[1].strip())\n",
    "df = pd.DataFrame(classes, columns=['description'])\n",
    "df.to_csv(\"vulnerability_descriptions.csv\", index=False, **csv_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
