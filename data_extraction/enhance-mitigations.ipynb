{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT_NAME = \"db_dialect\"\n",
    "\n",
    "csv.register_dialect(\n",
    "    DIALECT_NAME,\n",
    "    delimiter=\",\",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 20  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = (\n",
    "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    ")\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vulnerable = load_dataset(\n",
    "    \"msc-smart-contract-auditing/vulnerable-functions-base\",\n",
    "    split=\"train\",\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below vulnerability audit contains an audit name, a description of a vulnerability and a mitigation.\n",
    "You need to improve the mitigation based on the information provided.\n",
    "1. Expand the mitigation in such a way that it is very comprehensive and easy to understand.\n",
    "2. Do not dumb it down, still use technical terms where necessary.\n",
    "3. Do not include the code blocks, but you could still use inline code for your explanation. Surround the inline code using single backticks.\n",
    "4. In your reponse do not quote the title of the vulnerability, add anything about the description or the code. Just output the enhanced mitigation\n",
    "5. Do not make up any information about the vulnerability that is not in the provided context.\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Vulnerability title: {}\n",
    "Vulnerability description:\n",
    "{}\n",
    "Vulnerability mitigation:\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Improved mitigation:\n",
    "\"\"\"\n",
    "\n",
    "query_template_empty = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below vulnerability audit contains an audit name and description of the vulnerability.\n",
    "Write one suggestion for the mitigation of the vulnerability.\n",
    "1. Expand the mitigation in such a way that it is very comprehensive and easy to understand.\n",
    "2. Do not dumb it down, still use technical terms where necessary.\n",
    "3. Do not include the code blocks, but you could still use inline code for your explanation. Surround the inline code using single backticks.\n",
    "4. In your reponse do not quote the title of the vulnerability, add anything about the description or the code. Just output the enhanced mitigation\n",
    "5. Do not make up any information about the vulnerability that is not in the provided context.\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Vulnerability title: {}\n",
    "Vulnerability description:\n",
    "{}\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Improved mitigation:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_template(row):\n",
    "    if row[\"recommendation\"] is None:\n",
    "        return query_template_empty.format(\n",
    "            row[\"name\"],\n",
    "            row[\"description\"].replace(\"\\\\n\", \"\\n\"),\n",
    "        )\n",
    "\n",
    "    return query_template.format(\n",
    "        row[\"name\"],\n",
    "        row[\"description\"].replace(\"\\\\n\", \"\\n\"),\n",
    "        row[\"recommendation\"].replace(\"\\\\n\", \"\\n\"),\n",
    "    )\n",
    "\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_vulnerable = dataset_vulnerable.to_pandas()\n",
    "queries = df_vulnerable.apply(apply_template, axis=1)\n",
    "queries = queries.drop(queries.index[534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(queries[188])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 100\n",
    "current_chunk = 0\n",
    "start = current_chunk * chunk_len\n",
    "end = (current_chunk + 1) * chunk_len\n",
    "\n",
    "with open(f\"enhanced-recommendation-{current_chunk}.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, dialect=DIALECT_NAME)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"recommendation\"])\n",
    "\n",
    "    for query in tqdm(queries[start:end], total=chunk_len):\n",
    "        inputs = tokenizer(query, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "        output_tokens = model.generate(\n",
    "            **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "        decoded_output = tokenizer.decode(\n",
    "            output_tokens[0],\n",
    "            skip_special_tokens=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "        mitigation = decoded_output.split(\"Improved mitigation:\\n\")[1].strip().replace(\"\\n\", \"\\\\n\")\n",
    "        writer.writerow([mitigation])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, query in enumerate(queries[399:400]):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "    output_tokens = model.generate(\n",
    "        **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    decoded_output = tokenizer.decode(\n",
    "        output_tokens[0], skip_special_tokens=True, pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    print(query)\n",
    "    recommendation = decoded_output.split(\"Improved mitigation:\\n\")[1].strip()#.replace(\"\\n\", \"\\\\n\")\n",
    "    print(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
