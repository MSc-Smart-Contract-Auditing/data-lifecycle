{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT_NAME = \"db_dialect\"\n",
    "\n",
    "csv.register_dialect(\n",
    "    DIALECT_NAME,\n",
    "    delimiter=\",\",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Llama patching release 2024.5\n",
      "   \\\\   /|    GPU: NVIDIA A30 MIG 2g.12gb. Max memory: 11.688 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 20  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = (\n",
    "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    ")\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vulnerable = load_dataset(\n",
    "    \"msc-smart-contract-audition/vulnerable-functions-base\",\n",
    "    split=\"train\",\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below vulnerability audit contains an audit name, a description of a vulnerability and a mitigation.\n",
    "You need to improve the mitigation based on the information provided.\n",
    "1. Expand the mitigation in such a way that it is very comprehensive and easy to understand.\n",
    "2. Do not dumb it down, still use technical terms where necessary.\n",
    "3. Do not include the code blocks, but you could still use inline code for your explanation. Surround the inline code using single backticks.\n",
    "4. In your reponse do not quote the title of the vulnerability, add anything about the description or the code. Just output the enhanced mitigation\n",
    "5. Do not make up any information about the vulnerability that is not in the provided context.\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Vulnerability title: {}\n",
    "Vulnerability description:\n",
    "{}\n",
    "Vulnerability mitigation:\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Improved mitigation:\n",
    "\"\"\"\n",
    "\n",
    "query_template_empty = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below vulnerability audit contains an audit name and description of the vulnerability.\n",
    "Write one suggestion for the mitigation of the vulnerability.\n",
    "1. Expand the mitigation in such a way that it is very comprehensive and easy to understand.\n",
    "2. Do not dumb it down, still use technical terms where necessary.\n",
    "3. Do not include the code blocks, but you could still use inline code for your explanation. Surround the inline code using single backticks.\n",
    "4. In your reponse do not quote the title of the vulnerability, add anything about the description or the code. Just output the enhanced mitigation\n",
    "5. Do not make up any information about the vulnerability that is not in the provided context.\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Vulnerability title: {}\n",
    "Vulnerability description:\n",
    "{}\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Improved mitigation:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\n",
      "curve admin can drain pool via reentrancy (equal to execute emergency withdraw and rug tokenmak fund by third party)\n"
     ]
    }
   ],
   "source": [
    "def apply_template(row):\n",
    "    if row[\"recommendation\"] is None:\n",
    "        return query_template_empty.format(\n",
    "            row[\"name\"],\n",
    "            row[\"description\"].replace(\"\\\\n\", \"\\n\"),\n",
    "        )\n",
    "\n",
    "    return query_template.format(\n",
    "        row[\"name\"],\n",
    "        row[\"description\"].replace(\"\\\\n\", \"\\n\"),\n",
    "        row[\"recommendation\"].replace(\"\\\\n\", \"\\n\"),\n",
    "    )\n",
    "\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_vulnerable = dataset_vulnerable.to_pandas()\n",
    "queries = df_vulnerable.apply(apply_template, axis=1)\n",
    "queries = queries.drop(queries.index[534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "The below vulnerability audit contains an audit name, a description of a vulnerability and a mitigation.\n",
      "You need to improve the mitigation based on the information provided.\n",
      "1. Expand the mitigation in such a way that it is very comprehensive and easy to understand.\n",
      "2. Do not dumb it down, still use technical terms where necessary.\n",
      "3. Do not include the code blocks, but you could still use inline code for your explanation. Surround the inline code using single backticks.\n",
      "4. In your reponse do not quote the title of the vulnerability, add anything about the description or the code. Just output the enhanced mitigation\n",
      "5. Do not make up any information about the vulnerability that is not in the provided context.\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Vulnerability title: If the vault's side token balance is 0 or a tiny amount, then most if not all IG Bear trades will revert due to incorrect check of computation error during delta hedge amount calculation\n",
      "Vulnerability description:\n",
      "When delta hedge amount is calculated in `FinanceIGDelta.deltaHedgeAmount`, the last step is to verify that delta hedge amount to sell is slightly more than vault's side token due to computation error. The check is the following:\n",
      "```\n",
      "    if (SignedMath.abs(tokensToSwap) > params.sideTokensAmount) {\n",
      "        if (SignedMath.abs(tokensToSwap) - params.sideTokensAmount < params.sideTokensAmount / 10000) {\n",
      "            tokensToSwap = SignedMath.revabs(params.sideTokensAmount, true);\n",
      "        }\n",
      "    }\n",
      "```\n",
      "\n",
      "The check works correctly most of the time, but if the vault's side token (param.sideTokensAmount) is 0 or close to it, then the check will always fail, because `0 / 10000 = 0` and unsigned amount can not be less than 0. This means that even tiny amount to sell (like 1 wei) will revert the transaction if the vault has 0 side tokens.\n",
      "Vault's side token is 0 when:\n",
      "the current price trades above high boundary (Kb)\n",
      "and IG Bull used liquidity equals 0\n",
      "In such situation, any IG bear trade doesn't impact hedge amount, but due to computation error will almost always result in tiny but non-0 side token amount to sell value, which will revert due to incorrect comparision described above.\n",
      "Vulnerability mitigation:\n",
      "Possibly check both relative (sideToken / 10000) and absolute (e.g. 1000 or side token UNIT / 10000) value. Alternatively, always limit side token to sell amount to max of side token balance when hedging (but needs additional research if that might create issues).<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "Improved mitigation:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(queries[188])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 100\n",
    "current_chunk = 0\n",
    "start = current_chunk * chunk_len\n",
    "end = (current_chunk + 1) * chunk_len\n",
    "\n",
    "with open(f\"enhanced-recommendation-{current_chunk}.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, dialect=DIALECT_NAME)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"recommendation\"])\n",
    "\n",
    "    for query in tqdm(queries[start:end], total=chunk_len):\n",
    "        inputs = tokenizer(query, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "        output_tokens = model.generate(\n",
    "            **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "        decoded_output = tokenizer.decode(\n",
    "            output_tokens[0],\n",
    "            skip_special_tokens=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "        mitigation = decoded_output.split(\"Improved mitigation:\\n\")[1].strip().replace(\"\\n\", \"\\\\n\")\n",
    "        writer.writerow([mitigation])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "The below vulnerability audit contains an audit name, a description of a vulnerability and a mitigation.\n",
      "You need to improve the mitigation based on the information provided.\n",
      "1. Expand the mitigation in such a way that it is very comprehensive and easy to understand.\n",
      "2. Do not dumb it down, still use technical terms where necessary.\n",
      "3. Do not include the code blocks, but you could still use inline code for your explanation. Surround the inline code using single backticks.\n",
      "4. In your reponse do not quote the title of the vulnerability, add anything about the description or the code. Just output the enhanced mitigation\n",
      "5. Do not make up any information about the vulnerability that is not in the provided context.\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Vulnerability title: Slashing during `LSTCalculatorBase.sol` deployment can show bad apr for months\n",
      "Vulnerability description:\n",
      "The contract `LSTCalculatorBase.sol` has some functions to calculate the rough APR expected from a liquid staking token. The contract is first deployed, and the first snapshot is taken after `APR_FILTER_INIT_INTERVAL_IN_SEC`, which is 9 days. It then calculates the APR between the deployment and this first snapshot, and uses that to initialize the APR value. It uses the function `calculateAnnualizedChangeMinZero` to do this calculation.\n",
      "The issue is that the function `calculateAnnualizedChangeMinZero` has a floor of 0. So if the backing of the LST decreases over that 9 days due to a slashing event in that interval, this function will return 0, and the initial APR and `baseApr` will be set to 0.\n",
      "The calculator is designed to update the APR at regular intervals of 3 days. However, the new apr is given a weight of 10% and the older apr is given a weight of 90% as seen below.\n",
      "```\n",
      "return ((priorValue * (1e18 - alpha)) + (currentValue * alpha)) / 1e18;\n",
      "```\n",
      "\n",
      "And alpha is hardcoded to 0.1. So if the initial APR starts at 0 due to a slashing event in the initial 9 day period, a large number of updates will be required to bring the APR up to the correct value.\n",
      "Assuming the correct APR of 6%, and an initial APR of 0%, we can calculate that it takes upto 28 updates to reflect close the correct APR. This transaltes to 84 days. So the wrong APR cann be shown for upto 3 months. Tha protocol uses these APR values to justify the allocation to the various protocols. Thus a wrong APR for months would mean the protocol would sub optimally allocate funds for months, losing potential yield.\n",
      "Vulnerability mitigation:\n",
      "It is recommended to initialize the APR with a specified value, rather than calculate it over the initial 9 days. 9 day window is not good enough to get an accurate APR, and can be easily manipulated by a slashing event.<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "Improved mitigation:\n",
      "\n",
      "To mitigate the vulnerability, it is recommended to initialize the APR with a specified value, rather than calculating it over the initial 9 days. This is because the 9-day window is not sufficient to accurately capture the APR, and can be easily manipulated by a slashing event.\n",
      "\n",
      "Instead, consider initializing the APR with a default value, such as a historical average APR or a conservative estimate of the expected APR. This will ensure that the APR is not set to an incorrect value due to a slashing event during the initial deployment period.\n",
      "\n",
      "Additionally, consider implementing a more robust APR calculation mechanism that takes into account the historical data and is less susceptible to manipulation. This could include using a moving average of the APR over a longer period, such as 30 or 60 days, to smooth out any fluctuations and provide a more accurate representation of the expected APR.\n",
      "\n",
      "It is also recommended to regularly review and update the APR calculation mechanism to ensure that it remains accurate and reliable. This could include monitoring the APR calculation for anomalies and adjusting the mechanism as needed to prevent any potential manipulation or errors.\n",
      "\n",
      "By initializing the APR with a specified value and implementing a more robust APR calculation mechanism, you can ensure that the protocol's allocation decisions are based on accurate and reliable APR values, and minimize the risk of sub-optimal allocation decisions due to incorrect APR values.\n"
     ]
    }
   ],
   "source": [
    "for idx, query in enumerate(queries[399:400]):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "    output_tokens = model.generate(\n",
    "        **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    decoded_output = tokenizer.decode(\n",
    "        output_tokens[0], skip_special_tokens=True, pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    print(query)\n",
    "    recommendation = decoded_output.split(\"Improved mitigation:\\n\")[1].strip()#.replace(\"\\n\", \"\\\\n\")\n",
    "    print(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
