{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT_NAME = \"db_dialect\"\n",
    "\n",
    "csv.register_dialect(\n",
    "    DIALECT_NAME,\n",
    "    delimiter=\",\",\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 20  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = (\n",
    "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    ")\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeblocks = pd.read_csv(\"/vol/bitbucket/kza23/cleaned-up-code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_verified = load_dataset(\n",
    "    \"msc-smart-contract-auditing/vulnerable-functions-base\",\n",
    "    split=\"train\",\n",
    "    name=\"verified-functions\",\n",
    "    escapechar=\"\\\\\",\n",
    ")\n",
    "\n",
    "verified_df = dataset_verified.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(verified_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Below are provided 1 or more code blocks from a smart contract. The task is to explain what is its purpose in plain English.\n",
    "\n",
    "1. Do NOT use any names of variables, names of parameters or names of functions. Just try to explain the general functionality.\n",
    "2. Explain what each codeblock does step by step.\n",
    "3. Give a high-level overview and purpose of the code.\n",
    "4. First explain the functionality of each code block and after all codeblocks are explained provide a high-level overview of the code over all.\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Code block to explain:\n",
    "{}<|eot_id|>\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Code functionality:\n",
    "Code block 1:\n",
    "1. \"\"\"\n",
    "\n",
    "template_verified = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Below is a single codeblock from a smart contract. The task is to explain what is its purpose in plain English.\n",
    "\n",
    "1. Do NOT use any names of variables, names of parameters or names of functions. Just try to explain the general functionality.\n",
    "2. Explain the function does step by step.\n",
    "3. Give a high-level overview and purpose of the function within a wider context.\n",
    "4. First explain the functionality of the code block and after provide a high-level overview of the code over all.\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Code block to explain:\n",
    "{}<|eot_id|>\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Code functionality:\n",
    "Code block 1:\n",
    "1. \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 100\n",
    "current_chunk = 0\n",
    "start = current_chunk * chunk_len\n",
    "end = (current_chunk + 1) * chunk_len\n",
    "\n",
    "with open(f\"functionality-{current_chunk}.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, dialect=DIALECT_NAME)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"functionality\"])\n",
    "\n",
    "    for codeblock in tqdm(codeblocks['code'][start:end], total=chunk_len):\n",
    "\n",
    "        print(codeblock.replace(\"\\\\n\", \"\\n\"))\n",
    "\n",
    "        prompt = template.format(codeblock.replace(\"\\\\n\", \"\\n\"))\n",
    "\n",
    "        input = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "\n",
    "        output_tokens = model.generate(\n",
    "            **input, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "        decoded_output_purpose = tokenizer.decode(\n",
    "            output_tokens[0],\n",
    "            skip_special_tokens=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "        functionality = decoded_output_purpose.split(\"Code functionality:\\n\")[1].strip()\n",
    "        writer.writerow([functionality.replace(\"\\n\", \"\\\\n\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 100\n",
    "current_chunk = 0\n",
    "start = current_chunk * chunk_len\n",
    "end = (current_chunk + 1) * chunk_len\n",
    "\n",
    "with open(f\"functionality-verified-{current_chunk}.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, dialect=DIALECT_NAME)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"functionality\"])\n",
    "\n",
    "    for codeblock in tqdm(verified_df['function'][start:end], total=chunk_len):\n",
    "\n",
    "        print(codeblock.replace(\"\\\\n\", \"\\n\"))\n",
    "        prompt = template_verified.format(codeblock.replace(\"\\\\n\", \"\\n\"))\n",
    "\n",
    "        input = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "\n",
    "        output_tokens = model.generate(\n",
    "            **input, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "        decoded_output_purpose = tokenizer.decode(\n",
    "            output_tokens[0],\n",
    "            skip_special_tokens=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "        functionality = decoded_output_purpose.split(\"Code functionality:\\n\")[1].strip()\n",
    "        writer.writerow([functionality.replace(\"\\n\", \"\\\\n\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "DIALECT_NAME = \"db_dialect\"\n",
    "csv.register_dialect(\n",
    "    DIALECT_NAME,\n",
    "    delimiter=\",\",\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    escapechar=\"\\\\\",\n",
    ")\n",
    "\n",
    "# Output file name\n",
    "output_file = 'functionality-verified.csv'\n",
    "header = True\n",
    "# Open the output file in write mode to create/overwrite it\n",
    "with open(output_file, 'w') as outfile:\n",
    "    # Iterate through each chunk file\n",
    "    for i in range(6):\n",
    "        input_file = f'../functionality-verified-{i}.csv'\n",
    "        print(f\"Processing {input_file}\")\n",
    "\n",
    "        # Read the input CSV file\n",
    "        df = pd.read_csv(input_file, dialect=DIALECT_NAME)\n",
    "\n",
    "        # For the first file, include the header\n",
    "        df.to_csv(output_file, mode='a', index=False, header=header)\n",
    "        header = False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
