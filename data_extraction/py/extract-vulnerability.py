from unsloth import FastLanguageModel
from datasets import load_dataset
import pandas as pd

max_seq_length = 20  # Choose any! We auto support RoPE Scaling internally!
dtype = (
    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+
)
load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/llama-3-8b-Instruct-bnb-4bit",
    max_seq_length=max_seq_length,
    dtype=dtype,
    load_in_4bit=load_in_4bit,
)

FastLanguageModel.for_inference(model)  # Enable native 2x faster inference

dataset_vulnerable = load_dataset(
    "msc-smart-contract-audition/vulnerable-functions-base",
    split="train",
    escapechar="\\",
)


query_template = """
<|begin_of_text|><|start_header_id|>system<|end_header_id|>
Given the below vulnerability description, provide a single vulnerability type which can be defined by multiple words.
It needs describes the vulnerability as accurate as possible while avoiding specifcs like contract names, function names, variable names, etc.
Do not explain the reason for your choice, or provide any additional context about the vulnerability itself (this includes notes, why you chose so). Do not add any text or characters like quotations<|eot_id|>
<|start_header_id|>user<|end_header_id|>
Vulnerability Description:
{}<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>
Vulnerability type:
"""


# Convert to pandas DataFrame
df_vulnerable = dataset_vulnerable.to_pandas()
queries = df_vulnerable["description"].apply(
    lambda x: query_template.format(x.replace("\\n", "\n"))
)
queries = queries.drop(queries.index[534])

from tqdm import tqdm

classes = []
for query in tqdm(queries):
    inputs = tokenizer(query, return_tensors="pt", truncation=True).to("cuda")
    output_tokens = model.generate(
        **inputs, max_new_tokens=32, pad_token_id=tokenizer.pad_token_id
    )
    decoded_output = tokenizer.decode(
        output_tokens[0], skip_special_tokens=True, pad_token_id=tokenizer.pad_token_id
    )
    classes.append(decoded_output.split("Vulnerability type:\n")[1].strip().lower())
    # print(decoded_output.split("Vulnerability type:\n")[1].strip())
df = pd.DataFrame(classes, columns=["type"])
df.to_csv("vulnerability_types.csv", index=False)
