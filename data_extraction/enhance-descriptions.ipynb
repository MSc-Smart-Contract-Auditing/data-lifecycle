{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT_NAME = \"db_dialect\"\n",
    "\n",
    "csv.register_dialect(\n",
    "    DIALECT_NAME,\n",
    "    delimiter=\",\",\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 20  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = (\n",
    "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    ")\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vulnerable = load_dataset(\n",
    "    \"msc-smart-contract-auditing/vulnerable-functions-base\",\n",
    "    split=\"train\",\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below vulnerability audit contains an audit name, a description of a vulnerability and code blocks which contain the vulnerability.\n",
    "You need to improve the description based on the information provided.\n",
    "1. Expand the description in such a way that it is very comprehensive and easy to understand.\n",
    "2. Do not dumb it down, still use technical terms where necessary.\n",
    "3. Do not include the code blocks, but you could still use inline code for your explanation. Surround the inline code using single backticks.\n",
    "4. In your reponse do not quote the title of the vulnerability.\n",
    "5. Do not make up any information about the vulnerability that is not in the provided context.\n",
    "6. Do not add your solution or mitigation to the issue.\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Vulnerability title: {}\n",
    "Vulnerability description:\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Improved description:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_template(row):\n",
    "    return query_template.format(\n",
    "        row[\"name\"],\n",
    "        row[\"description\"].replace(\"\\\\n\", \"\\n\"),\n",
    "    )\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_vulnerable = dataset_vulnerable.to_pandas()\n",
    "queries = df_vulnerable.apply(apply_template, axis=1)\n",
    "queries = queries.drop(queries.index[534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(queries[188])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vulnerability_descriptions.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f, dialect=DIALECT_NAME)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"description\"])\n",
    "\n",
    "    # Process each query and write the result to the file\n",
    "    # for query in tqdm(queries):\n",
    "    for idx, query in enumerate(queries[:10]):\n",
    "        inputs = tokenizer(query, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "        output_tokens = model.generate(\n",
    "            **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "        decoded_output = tokenizer.decode(\n",
    "            output_tokens[0], skip_special_tokens=True, pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "        description = decoded_output.split(\"Improved description:\\n\")[1].strip()#.replace(\"\\n\", \"\\\\n\")\n",
    "        # Write the description to the CSV file\n",
    "        # writer.writerow([description])\n",
    "        print(\"Original: \", df_vulnerable.iloc[idx][\"description\"])\n",
    "        print(\"Imrpoved: \")\n",
    "        print(description)\n",
    "        print(\"====\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
