{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT_NAME = \"db_dialect\"\n",
    "\n",
    "csv.register_dialect(\n",
    "    DIALECT_NAME,\n",
    "    delimiter=\",\",\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 20  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = (\n",
    "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    ")\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vulnerable = load_dataset(\n",
    "    \"msc-smart-contract-auditing/vulnerable-functions-base\",\n",
    "    split=\"train\",\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below is a code blocks which might have improper formatting. The task is to fix the formatting and remove comments which do not describe the code. Apart from formatting all of the code needs to remain the same.\n",
    "\n",
    "1. Ensure that the code is properly indented.\n",
    "2. Ensure that there are no leading tabs - the outer most block should start with no whitespace infront.\n",
    "3. If a line is too long break it in multiple lines.\n",
    "4. Keep all the code the same even if it seems unnecessary in the context.\n",
    "5. Remove comments which contain no information about the code.\n",
    "6. Remove any comments which contain URLs.\n",
    "7. Do not add any backticks as this will be done automatically. If you do it will break the formatting. DO NOT ADD BACKTICKS.\n",
    "\n",
    "Do not explain your changes at the end just output the formatted code block.\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Code block:\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Formatted code block:\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_codeblocks(description):\n",
    "    codeblocks = []\n",
    "    codeblock = \"\"\n",
    "\n",
    "    writing = False\n",
    "\n",
    "    for line in description.split(\"\\n\"):\n",
    "        if line.strip().startswith(\"```\"):\n",
    "            if writing:\n",
    "                codeblocks.append(codeblock)\n",
    "                yield codeblock\n",
    "                codeblock = \"\"\n",
    "                writing = False\n",
    "            else:\n",
    "                writing = True\n",
    "            continue\n",
    "\n",
    "        if writing:\n",
    "            codeblock += line + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame and drop 534 (too long)\n",
    "descriptions = dataset_vulnerable.to_pandas().drop(index=534)['description'].apply(lambda row: row.replace(\"\\\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 100\n",
    "current_chunk = 0\n",
    "start = current_chunk * chunk_len\n",
    "end = (current_chunk + 1) * chunk_len\n",
    "\n",
    "with open(f\"cleaned-up-code-{current_chunk+1}.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, dialect=DIALECT_NAME)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"code\"])\n",
    "\n",
    "    for description in tqdm(descriptions[start:end], total=chunk_len):\n",
    "        formatted_blocks = []\n",
    "        for codeblock in extract_codeblocks(description):\n",
    "            prompt = fix_template.format(codeblock)\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "            output_tokens = model.generate(\n",
    "                **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "            decoded_output = tokenizer.decode(\n",
    "                output_tokens[0],\n",
    "                skip_special_tokens=True,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "            )\n",
    "\n",
    "            raw_output = decoded_output.split(\"Formatted code block:\\n\")[1].strip()\n",
    "            formatted_blocks.append(\n",
    "                f\"```\\n{raw_output}\\n```\"\n",
    "            )\n",
    "        codeblocks = \"\\n\".join(formatted_blocks).replace(\"\\n\", \"\\\\n\")\n",
    "        writer.writerow([codeblocks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below is a code blocks which might have improper formatting. The task is to fix the formatting and remove comments which do not describe the code. Apart from formatting all of the code needs to remain the same.\n",
    "1. Ensure that the code is properly indented.\n",
    "2. Ensure that there are no leading tabs - the outer most block should start with no whitespace infront.\n",
    "3. If a line is too long break it in multiple lines.\n",
    "4. Keep all the code the same even if it seems unnecessary in the context.\n",
    "5. Remove comments which contain no information about the code.\n",
    "6. Remove any comments which contain URLs.\n",
    "\n",
    "Do not explain your changes at the end just output the formatted code block.\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Code block:\n",
    "```\n",
    "    // File input.sol:12\n",
    "            uint inputTotalUSDValueE36;\n",
    "                for (uint i; i < openTokenInfos.length; ) {\n",
    "                 inputTotalUSDValueE36 += openTokenInfos[i].inputAmt * tokenPriceE36s[i];\n",
    "                      borrowTotalUSDValueE36 += openTokenInfos[i].borrowAmt * tokenPriceE36s[i];\n",
    "                 unchecked {\n",
    "            ++i; // See https://github.com/MSc-Smart-Contract-Audition/data-scraper/blob/main/verified/src/compile_contracts.py\n",
    "                }\n",
    "            }\n",
    "                // 1.3 calculate net pnl (including strategy users & borrow profit)\n",
    "            positionOpenUSDValueE36 = inputTotalUSDValueE36 + borrowTotalUSDValueE36;\n",
    "            netPnLE36 = positionCurUSDValueE36.toInt256() - positionOpenUSDValueE36.toInt256();\n",
    "```\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Formatted code block:\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer(fix_template, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "output_tokens = model.generate(\n",
    "    **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "decoded_output = tokenizer.decode(\n",
    "    output_tokens[0], skip_special_tokens=True, pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "\n",
    "print(decoded_output.split(\"Formatted code block:\\n\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_codeblocks(description):\n",
    "    codeblock = \"\"\n",
    "\n",
    "    writing = False\n",
    "\n",
    "    for line in description.split(\"\\n\"):\n",
    "        if line.strip().startswith(\"```\"):\n",
    "            if writing:\n",
    "                yield codeblock\n",
    "                codeblock = \"\"\n",
    "                writing = False\n",
    "            else:\n",
    "                writing = True\n",
    "            continue\n",
    "\n",
    "        if writing:\n",
    "            codeblock += line + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"function sellUnderlying\"\n",
    "\n",
    "item = descriptions[descriptions.str.contains(content)].iloc[0]\n",
    "\n",
    "# item = descriptions.iloc[0]\n",
    "\n",
    "# print(item)\n",
    "\n",
    "formatted_blocks = []\n",
    "for codeblock in extract_codeblocks(item):\n",
    "\n",
    "    print(\"CODEBLOCK:\", codeblock)\n",
    "    print(\"====\")\n",
    "\n",
    "    prompt = fix_template.format(codeblock)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "    output_tokens = model.generate(\n",
    "        **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    decoded_output = tokenizer.decode(\n",
    "        output_tokens[0],\n",
    "        skip_special_tokens=True,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "    raw_output = decoded_output.split(\"Formatted code block:\\n\")[1].strip()\n",
    "\n",
    "    if not raw_output.startswith(\"```\"):\n",
    "        raw_output = \"```\\n\" + raw_output\n",
    "    if not raw_output.endswith(\"```\"):\n",
    "        raw_output += \"\\n```\"\n",
    "\n",
    "    formatted_blocks.append(raw_output)\n",
    "\n",
    "print(len(formatted_blocks))\n",
    "\n",
    "codeblocks = \"\\n\".join(formatted_blocks)#.replace(\"\\n\", \"\\\\n\")\n",
    "print(codeblocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "DIALECT_NAME = \"db_dialect\"\n",
    "csv.register_dialect(\n",
    "    DIALECT_NAME,\n",
    "    delimiter=\",\",\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    escapechar=\"\\\\\",\n",
    ")\n",
    "\n",
    "# Output file name\n",
    "output_file = 'cleaned-up-code.csv'\n",
    "header = True\n",
    "# Open the output file in write mode to create/overwrite it\n",
    "with open(output_file, 'w') as outfile:\n",
    "    # Iterate through each chunk file\n",
    "    for i in range(21):\n",
    "        input_file = f'../cleaned-up-code-{i}.csv'\n",
    "        print(f\"Processing {input_file}\")\n",
    "\n",
    "        # Read the input CSV file\n",
    "        df = pd.read_csv(input_file, dialect=DIALECT_NAME)\n",
    "\n",
    "        # For the first file, include the header\n",
    "        df.to_csv(output_file, mode='a', index=False, header=header)\n",
    "        header = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1 = \"\"\"\n",
    "```\\\\n```\\\\n{\\\\n  \\\"@openzeppelin/contracts\\\": \\\"4.3.1\\\"\\,\\\\n  \\\"@openzeppelin/test-helpers\\\": \\\"0.5.6\\\"\\,\\\\n  \\\"@openzeppelin/contracts-upgradeable\\\": \\\"4.3.1\\\"\\\\n}\\\\n```\\\\n```\n",
    "\"\"\"\n",
    "\n",
    "test2 = \"\"\"\n",
    "365,\"```\\n{\\n  \"\"@openzeppelin/contracts\"\": \"\"4.3.1\"\",\\n  \"\"@openzeppelin/test-helpers\"\": \"\"0.5.6\"\",\\n  \"\"@openzeppelin/contracts-upgradeable\"\": \"\"4.3.1\"\"\\n}\\n```\",\"The UUPSUpgradeable vulnerability is a critical severity bug discovered in OpenZeppelin's contracts, specifically in versions 4.1.0 to 4.3.1. The affected contracts include `@openzeppelin/contracts` and `@openzeppelin/contracts-upgradeable`, which are widely used in the kyber-swap contracts, as evident from the `package.json` file.\\n\\nThe vulnerability allows an attacker to manipulate the upgrade process of UUPSUpgradeable contracts, enabling them to execute arbitrary code during the upgrade process. This can lead to unauthorized changes to the contract's behavior, potentially resulting in the theft of funds or unauthorized access to sensitive data.\\n\\nThe affected contracts, `PoolOracle.sol` and `TokenPositionDescriptor.sol`, are both UUPSUpgradeable and require immediate attention to ensure the security of the kyber-swap contracts. It is essential to upgrade these contracts to a fixed version, specifically `@openzeppelin/contracts` version 4.3.2 or higher, and `@openzeppelin/contracts-upgradeable` version 4.3.2 or higher, to mitigate this vulnerability.\",\"To mitigate the UUPSUpgradeable vulnerability in OpenZeppelin Contracts, follow these steps:nn1. **Update the OpenZeppelin library to the latest version**: Ensure that you are using the latest version of the OpenZeppelin Contracts library, which is version 4.3.2 or higher. This will ensure that you have the fix for the UUPSUpgradeable vulnerability.nn2. **Verify the UUPS implementation contracts**: Review the OpenZeppelin UUPS documentation to understand the correct implementation of UUPSUpgradeable contracts. This will help you identify any potential issues and ensure that your contracts are properly configured.nn3. **Check the affected contracts**: Identify the contracts that are affected by the UUPSUpgradeable vulnerability, such as PoolOracle.sol and TokenPositionDescriptor.sol. Review the code and ensure that they are using the latest version of the OpenZeppelin Contracts library.nn4. **Implement the UUPSUpgradeable contracts correctly**: Follow the OpenZeppelin UUPS documentation to implement the UUPSUpgradeable contracts correctly. This includes setting the `UUPSUpgradeable` contract as the base contract for your upgradeable contracts.nn5. **Test the UUPSUpgradeable contracts**: Thoroughly test the UUPSUpgradeable contracts to ensure that they are functioning correctly and that the upgrade process is working as expected.nn6. **Monitor the UUPSUpgradeable contracts**: Continuously monitor the UUPSUpgradeable contracts to ensure that they are not vulnerable to any new attacks or exploits.nnBy following these steps, you can effectively mitigate the UUPSUpgradeable vulnerability in OpenZeppelin Contracts and ensure the security of your smart contracts.\",upgradeable contract vulnerability\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(test1.replace('\\\\n', '\\n'))\n",
    "print(test2.replace('\\\\n', '\\n'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
