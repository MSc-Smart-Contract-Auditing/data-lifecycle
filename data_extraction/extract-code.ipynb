{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT_NAME = \"db_dialect\"\n",
    "\n",
    "csv.register_dialect(\n",
    "    DIALECT_NAME,\n",
    "    delimiter=\",\",\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Llama patching release 2024.5\n",
      "   \\\\   /|    GPU: NVIDIA A30 MIG 2g.12gb. Max memory: 11.688 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25.post1. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 20  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = (\n",
    "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    ")\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.51k/2.51k [00:00<00:00, 16.5MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.91M/6.91M [00:00<00:00, 16.2MB/s]\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1972/1972 [00:00<00:00, 4632.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_vulnerable = load_dataset(\n",
    "    \"msc-smart-contract-audition/vulnerable-functions-base\",\n",
    "    split=\"train\",\n",
    "    escapechar=\"\\\\\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below is a code blocks which might have improper formatting. The task is to fix the formatting and remove comments which do not describe the code. Apart from formatting all of the code needs to remain the same.\n",
    "\n",
    "1. Ensure that the code is properly indented.\n",
    "2. Ensure that there are no leading tabs - the outer most block should start with no whitespace infront.\n",
    "3. If a line is too long break it in multiple lines.\n",
    "4. Keep all the code the same even if it seems unnecessary in the context.\n",
    "5. Remove comments which contain no information about the code.\n",
    "6. Remove any comments which contain URLs.\n",
    "7. Do not add any backticks as this will be done automatically. If you do it will break the formatting. DO NOT ADD BACKTICKS.\n",
    "\n",
    "Do not explain your changes at the end just output the formatted code block.\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Code block:\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Formatted code block:\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_codeblocks(description):\n",
    "    codeblocks = []\n",
    "    codeblock = \"\"\n",
    "\n",
    "    writing = False\n",
    "\n",
    "    for line in description.split(\"\\n\"):\n",
    "        if line.strip().startswith(\"```\"):\n",
    "            if writing:\n",
    "                codeblocks.append(codeblock)\n",
    "                yield codeblock\n",
    "                codeblock = \"\"\n",
    "                writing = False\n",
    "            else:\n",
    "                writing = True\n",
    "            continue\n",
    "\n",
    "        if writing:\n",
    "            codeblock += line + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame and drop 534 (too long)\n",
    "descriptions = dataset_vulnerable.to_pandas().drop(index=534)['description'].apply(lambda row: row.replace(\"\\\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "(\n",
      "    netPnLE36,\n",
      "    lenderProfitUSDValueE36,\n",
      "    borrowTotalUSDValueE36,\n",
      "    positionOpenUSDValueE36,\n",
      "    sharingProfitTokenAmts\n",
      ") = calcProfitInfo(_positionManager, _user, _posId);\n",
      "\n",
      "// 2. add liquidation premium to the shared profit amounts\n",
      "uint lenderLiquidationPremiumBPS = IConfig(config).lenderLiquidatePremiumBPS();\n",
      "\n",
      "for (uint i = 0; i < sharingProfitTokenAmts.length; i++) {\n",
      "    sharingProfitTokenAmts[i] += (pos.openTokenInfos[i].borrowAmt * lenderLiquidationPremiumBPS) / BPS;\n",
      "}\n",
      "```\n",
      "```\n",
      "function _shareProfitsAndRepayAllDebts(\n",
      "    address _positionManager,\n",
      "    address _posOwner,\n",
      "    uint _posId,\n",
      "    int _netPnLE36,\n",
      "    uint[] memory _shareProfitAmts,\n",
      "    address[] memory _tokens,\n",
      "    OpenTokenInfo[] memory _openTokenInfos\n",
      ") internal {\n",
      "    // 0. load states\n",
      "    address _lendingProxy = lendingProxy;\n",
      "\n",
      "    // 1. if net pnl is positive, share profits to lending proxy\n",
      "    if (_netPnLE36 > 0) {\n",
      "        for (uint i = 0; i < _shareProfitAmts.length; i++) {\n",
      "            if (_shareProfitAmts[i] > 0) {\n",
      "                ILendingProxy(_lendingProxy).shareProfit(_tokens[i], _shareProfitAmts[i]);\n",
      "            }\n",
      "        }\n",
      "        emit ProfitShared(_posOwner, _posId, _tokens, _shareProfitAmts);\n",
      "    }\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 0/100 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m prompt \u001b[38;5;241m=\u001b[39m fix_template\u001b[38;5;241m.\u001b[39mformat(codeblock)\n\u001b[1;32m     16\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m decoded_output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m     21\u001b[0m     output_tokens[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     22\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m raw_output \u001b[38;5;241m=\u001b[39m decoded_output\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormatted code block:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/unsloth/models/llama.py:987\u001b[0m, in \u001b[0;36m_wrap_fast_inference.<locals>._fast_generate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# Autocasted\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m device_type, dtype \u001b[38;5;241m=\u001b[39m dtype):\n\u001b[0;32m--> 987\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# Unset a flag for generation!\u001b[39;00m\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/transformers/generation/utils.py:1610\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assisted_decoding(\n\u001b[1;32m   1594\u001b[0m         input_ids,\n\u001b[1;32m   1595\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1607\u001b[0m     )\n\u001b[1;32m   1608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1609\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1610\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/transformers/generation/utils.py:2578\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2571\u001b[0m         streamer\u001b[38;5;241m.\u001b[39mput(next_tokens\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m   2572\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   2573\u001b[0m         outputs,\n\u001b[1;32m   2574\u001b[0m         model_kwargs,\n\u001b[1;32m   2575\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2576\u001b[0m     )\n\u001b[0;32m-> 2578\u001b[0m     unfinished_sequences \u001b[38;5;241m=\u001b[39m unfinished_sequences \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m~\u001b[39m\u001b[43mstopping_criteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2579\u001b[0m     this_peer_finished \u001b[38;5;241m=\u001b[39m unfinished_sequences\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streamer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/transformers/generation/stopping_criteria.py:504\u001b[0m, in \u001b[0;36mStoppingCriteriaList.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m is_done \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), \u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m criteria \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 504\u001b[0m     is_done \u001b[38;5;241m=\u001b[39m is_done \u001b[38;5;241m|\u001b[39m \u001b[43mcriteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_done\n",
      "File \u001b[0;32m/vol/bitbucket/kza23/msc/lib/python3.10/site-packages/transformers/generation/stopping_criteria.py:495\u001b[0m, in \u001b[0;36mEosTokenCriteria.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     is_done \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    487\u001b[0m         input_ids[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;241m.\u001b[39mtile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token_id\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    493\u001b[0m     )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     is_done \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misin(input_ids[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_done\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chunk_len = 100\n",
    "current_chunk = 0\n",
    "start = current_chunk * chunk_len\n",
    "end = (current_chunk + 1) * chunk_len\n",
    "\n",
    "with open(f\"cleaned-up-code-{current_chunk+1}.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f, dialect=DIALECT_NAME)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"code\"])\n",
    "\n",
    "    for description in tqdm(descriptions[start:end], total=chunk_len):\n",
    "        formatted_blocks = []\n",
    "        for codeblock in extract_codeblocks(description):\n",
    "            prompt = fix_template.format(codeblock)\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "            output_tokens = model.generate(\n",
    "                **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "            decoded_output = tokenizer.decode(\n",
    "                output_tokens[0],\n",
    "                skip_special_tokens=True,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "            )\n",
    "\n",
    "            raw_output = decoded_output.split(\"Formatted code block:\\n\")[1].strip()\n",
    "            formatted_blocks.append(\n",
    "                f\"```\\n{raw_output}\\n```\"\n",
    "            )\n",
    "        codeblocks = \"\\n\".join(formatted_blocks).replace(\"\\n\", \"\\\\n\")\n",
    "        writer.writerow([codeblocks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "uint inputTotalUSDValueE36;\n",
      "\n",
      "for (uint i; i < openTokenInfos.length; ) {\n",
      "    inputTotalUSDValueE36 += openTokenInfos[i].inputAmt * tokenPriceE36s[i];\n",
      "    borrowTotalUSDValueE36 += openTokenInfos[i].borrowAmt * tokenPriceE36s[i];\n",
      "    unchecked {\n",
      "        ++i;\n",
      "    }\n",
      "}\n",
      "\n",
      "positionOpenUSDValueE36 = inputTotalUSDValueE36 + borrowTotalUSDValueE36;\n",
      "netPnLE36 = positionCurUSDValueE36.toInt256() - positionOpenUSDValueE36.toInt256();\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "fix_template = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "The below is a code blocks which might have improper formatting. The task is to fix the formatting and remove comments which do not describe the code. Apart from formatting all of the code needs to remain the same.\n",
    "1. Ensure that the code is properly indented.\n",
    "2. Ensure that there are no leading tabs - the outer most block should start with no whitespace infront.\n",
    "3. If a line is too long break it in multiple lines.\n",
    "4. Keep all the code the same even if it seems unnecessary in the context.\n",
    "5. Remove comments which contain no information about the code.\n",
    "6. Remove any comments which contain URLs.\n",
    "\n",
    "Do not explain your changes at the end just output the formatted code block.\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Code block:\n",
    "```\n",
    "    // File input.sol:12\n",
    "            uint inputTotalUSDValueE36;\n",
    "                for (uint i; i < openTokenInfos.length; ) {\n",
    "                 inputTotalUSDValueE36 += openTokenInfos[i].inputAmt * tokenPriceE36s[i];\n",
    "                      borrowTotalUSDValueE36 += openTokenInfos[i].borrowAmt * tokenPriceE36s[i];\n",
    "                 unchecked {\n",
    "            ++i; // See https://github.com/MSc-Smart-Contract-Audition/data-scraper/blob/main/verified/src/compile_contracts.py\n",
    "                }\n",
    "            }\n",
    "                // 1.3 calculate net pnl (including strategy users & borrow profit)\n",
    "            positionOpenUSDValueE36 = inputTotalUSDValueE36 + borrowTotalUSDValueE36;\n",
    "            netPnLE36 = positionCurUSDValueE36.toInt256() - positionOpenUSDValueE36.toInt256();\n",
    "```\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "Formatted code block:\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer(fix_template, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "output_tokens = model.generate(\n",
    "    **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "decoded_output = tokenizer.decode(\n",
    "    output_tokens[0], skip_special_tokens=True, pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "\n",
    "print(decoded_output.split(\"Formatted code block:\\n\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_codeblocks(description):\n",
    "    codeblock = \"\"\n",
    "\n",
    "    writing = False\n",
    "\n",
    "    for line in description.split(\"\\n\"):\n",
    "        if line.strip().startswith(\"```\"):\n",
    "            if writing:\n",
    "                yield codeblock\n",
    "                codeblock = \"\"\n",
    "                writing = False\n",
    "            else:\n",
    "                writing = True\n",
    "            continue\n",
    "\n",
    "        if writing:\n",
    "            codeblock += line + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODEBLOCK:     function sellUnderlying(\n",
      "        address u,\n",
      "        uint256 m,\n",
      "        uint128 a,\n",
      "        uint128 s\n",
      "    ) external returns (uint128) {\n",
      "        // Get the pool for the market\n",
      "        IPool pool = IPool(pools[u][m]);\n",
      "\n",
      "        // Get the number of PTs received for selling `a` underlying tokens\n",
      "        uint128 expected = pool.sellBasePreview(a);\n",
      "\n",
      "        // Verify slippage does not exceed the one set by the user\n",
      "        if (expected < s) {\n",
      "            revert Exception(16, expected, 0, address(0), address(0));\n",
      "        }\n",
      "\n",
      "        // Transfer the underlying tokens to the pool\n",
      "        Safe.transferFrom(IERC20(pool.base()), msg.sender, address(pool), a);\n",
      "// rest of code\n",
      "    function sellPrincipalToken(\n",
      "        address u,\n",
      "        uint256 m,\n",
      "        uint128 a,\n",
      "        uint128 s\n",
      "    ) external returns (uint128) {\n",
      "        // Get the pool for the market\n",
      "        IPool pool = IPool(pools[u][m]);\n",
      "\n",
      "        // Preview amount of underlying received by selling `a` PTs\n",
      "        uint256 expected = pool.sellFYTokenPreview(a);\n",
      "\n",
      "        // Verify that the amount needed does not exceed the slippage parameter\n",
      "        if (expected < s) {\n",
      "            revert Exception(16, expected, s, address(0), address(0));\n",
      "        }\n",
      "\n",
      "        // Transfer the principal tokens to the pool\n",
      "        Safe.transferFrom(\n",
      "            IERC20(address(pool.fyToken())),\n",
      "            msg.sender,\n",
      "            address(pool),\n",
      "            a\n",
      "        );\n",
      "\n",
      "====\n",
      "CODEBLOCK:         vm.startPrank(address(token));\n",
      "        IERC20(Contracts.USDC).approve(address(marketplace), type(uint256).max);\n",
      "        IERC20(Contracts.YIELD_TOKEN).approve(\n",
      "            address(marketplace),\n",
      "            type(uint256).max\n",
      "        );\n",
      "\n",
      "====\n",
      "2\n",
      "```\n",
      "function sellUnderlying(\n",
      "    address u,\n",
      "    uint256 m,\n",
      "    uint128 a,\n",
      "    uint128 s\n",
      ") external returns (uint128) {\n",
      "    IPool pool = IPool(pools[u][m]);\n",
      "\n",
      "    uint128 expected = pool.sellBasePreview(a);\n",
      "\n",
      "    if (expected < s) {\n",
      "        revert Exception(16, expected, 0, address(0), address(0));\n",
      "    }\n",
      "\n",
      "    Safe.transferFrom(IERC20(pool.base()), msg.sender, address(pool), a);\n",
      "}\n",
      "\n",
      "function sellPrincipalToken(\n",
      "    address u,\n",
      "    uint256 m,\n",
      "    uint128 a,\n",
      "    uint128 s\n",
      ") external returns (uint128) {\n",
      "    IPool pool = IPool(pools[u][m]);\n",
      "\n",
      "    uint256 expected = pool.sellFYTokenPreview(a);\n",
      "\n",
      "    if (expected < s) {\n",
      "        revert Exception(16, expected, s, address(0), address(0));\n",
      "    }\n",
      "\n",
      "    Safe.transferFrom(\n",
      "        IERC20(address(pool.fyToken())),\n",
      "        msg.sender,\n",
      "        address(pool),\n",
      "        a\n",
      "    );\n",
      "}\n",
      "```\n",
      "```\n",
      "vm.startPrank(address(token))\n",
      "IERC20(Contracts.USDC).approve(address(marketplace), type(uint256).max)\n",
      "IERC20(Contracts.YIELD_TOKEN).approve(\n",
      "    address(marketplace),\n",
      "    type(uint256).max\n",
      ")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "content = \"function sellUnderlying\"\n",
    "\n",
    "item = descriptions[descriptions.str.contains(content)].iloc[0]\n",
    "\n",
    "# item = descriptions.iloc[0]\n",
    "\n",
    "# print(item)\n",
    "\n",
    "formatted_blocks = []\n",
    "for codeblock in extract_codeblocks(item):\n",
    "\n",
    "    print(\"CODEBLOCK:\", codeblock)\n",
    "    print(\"====\")\n",
    "\n",
    "    prompt = fix_template.format(codeblock)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "    output_tokens = model.generate(\n",
    "        **inputs, max_new_tokens=512, pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    decoded_output = tokenizer.decode(\n",
    "        output_tokens[0],\n",
    "        skip_special_tokens=True,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "    raw_output = decoded_output.split(\"Formatted code block:\\n\")[1].strip()\n",
    "\n",
    "    if not raw_output.startswith(\"```\"):\n",
    "        raw_output = \"```\\n\" + raw_output\n",
    "    if not raw_output.endswith(\"```\"):\n",
    "        raw_output += \"\\n```\"\n",
    "\n",
    "    formatted_blocks.append(raw_output)\n",
    "\n",
    "print(len(formatted_blocks))\n",
    "\n",
    "codeblocks = \"\\n\".join(formatted_blocks)#.replace(\"\\n\", \"\\\\n\")\n",
    "print(codeblocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../cleaned-up-code-0.csv\n",
      "Processing ../cleaned-up-code-1.csv\n",
      "Processing ../cleaned-up-code-2.csv\n",
      "Processing ../cleaned-up-code-3.csv\n",
      "Processing ../cleaned-up-code-4.csv\n",
      "Processing ../cleaned-up-code-5.csv\n",
      "Processing ../cleaned-up-code-6.csv\n",
      "Processing ../cleaned-up-code-7.csv\n",
      "Processing ../cleaned-up-code-8.csv\n",
      "Processing ../cleaned-up-code-9.csv\n",
      "Processing ../cleaned-up-code-10.csv\n",
      "Processing ../cleaned-up-code-11.csv\n",
      "Processing ../cleaned-up-code-12.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../cleaned-up-code-12.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Read the input CSV file\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDIALECT_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# For the first file, include the header\u001b[39;00m\n\u001b[1;32m     26\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(output_file, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39mheader)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../cleaned-up-code-12.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "DIALECT_NAME = \"db_dialect\"\n",
    "csv.register_dialect(\n",
    "    DIALECT_NAME,\n",
    "    delimiter=\",\",\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    escapechar=\"\\\\\",\n",
    ")\n",
    "\n",
    "# Output file name\n",
    "output_file = 'cleaned-up-code.csv'\n",
    "header = True\n",
    "# Open the output file in write mode to create/overwrite it\n",
    "with open(output_file, 'w') as outfile:\n",
    "    # Iterate through each chunk file\n",
    "    for i in range(21):\n",
    "        input_file = f'../cleaned-up-code-{i}.csv'\n",
    "        print(f\"Processing {input_file}\")\n",
    "\n",
    "        # Read the input CSV file\n",
    "        df = pd.read_csv(input_file, dialect=DIALECT_NAME)\n",
    "\n",
    "        # For the first file, include the header\n",
    "        df.to_csv(output_file, mode='a', index=False, header=header)\n",
    "        header = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```\n",
      "```\n",
      "{\n",
      "  \"@openzeppelin/contracts\": \"4.3.1\"\\,\n",
      "  \"@openzeppelin/test-helpers\": \"0.5.6\"\\,\n",
      "  \"@openzeppelin/contracts-upgradeable\": \"4.3.1\"\n",
      "}\n",
      "```\n",
      "```\n",
      "\n",
      "\n",
      "365,\"```\n",
      "{\n",
      "  \"\"@openzeppelin/contracts\"\": \"\"4.3.1\"\",\n",
      "  \"\"@openzeppelin/test-helpers\"\": \"\"0.5.6\"\",\n",
      "  \"\"@openzeppelin/contracts-upgradeable\"\": \"\"4.3.1\"\"\n",
      "}\n",
      "```\",\"The UUPSUpgradeable vulnerability is a critical severity bug discovered in OpenZeppelin's contracts, specifically in versions 4.1.0 to 4.3.1. The affected contracts include `@openzeppelin/contracts` and `@openzeppelin/contracts-upgradeable`, which are widely used in the kyber-swap contracts, as evident from the `package.json` file.\n",
      "\n",
      "The vulnerability allows an attacker to manipulate the upgrade process of UUPSUpgradeable contracts, enabling them to execute arbitrary code during the upgrade process. This can lead to unauthorized changes to the contract's behavior, potentially resulting in the theft of funds or unauthorized access to sensitive data.\n",
      "\n",
      "The affected contracts, `PoolOracle.sol` and `TokenPositionDescriptor.sol`, are both UUPSUpgradeable and require immediate attention to ensure the security of the kyber-swap contracts. It is essential to upgrade these contracts to a fixed version, specifically `@openzeppelin/contracts` version 4.3.2 or higher, and `@openzeppelin/contracts-upgradeable` version 4.3.2 or higher, to mitigate this vulnerability.\",\"To mitigate the UUPSUpgradeable vulnerability in OpenZeppelin Contracts, follow these steps:nn1. **Update the OpenZeppelin library to the latest version**: Ensure that you are using the latest version of the OpenZeppelin Contracts library, which is version 4.3.2 or higher. This will ensure that you have the fix for the UUPSUpgradeable vulnerability.nn2. **Verify the UUPS implementation contracts**: Review the OpenZeppelin UUPS documentation to understand the correct implementation of UUPSUpgradeable contracts. This will help you identify any potential issues and ensure that your contracts are properly configured.nn3. **Check the affected contracts**: Identify the contracts that are affected by the UUPSUpgradeable vulnerability, such as PoolOracle.sol and TokenPositionDescriptor.sol. Review the code and ensure that they are using the latest version of the OpenZeppelin Contracts library.nn4. **Implement the UUPSUpgradeable contracts correctly**: Follow the OpenZeppelin UUPS documentation to implement the UUPSUpgradeable contracts correctly. This includes setting the `UUPSUpgradeable` contract as the base contract for your upgradeable contracts.nn5. **Test the UUPSUpgradeable contracts**: Thoroughly test the UUPSUpgradeable contracts to ensure that they are functioning correctly and that the upgrade process is working as expected.nn6. **Monitor the UUPSUpgradeable contracts**: Continuously monitor the UUPSUpgradeable contracts to ensure that they are not vulnerable to any new attacks or exploits.nnBy following these steps, you can effectively mitigate the UUPSUpgradeable vulnerability in OpenZeppelin Contracts and ensure the security of your smart contracts.\",upgradeable contract vulnerability\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test1 = \"\"\"\n",
    "```\\\\n```\\\\n{\\\\n  \\\"@openzeppelin/contracts\\\": \\\"4.3.1\\\"\\,\\\\n  \\\"@openzeppelin/test-helpers\\\": \\\"0.5.6\\\"\\,\\\\n  \\\"@openzeppelin/contracts-upgradeable\\\": \\\"4.3.1\\\"\\\\n}\\\\n```\\\\n```\n",
    "\"\"\"\n",
    "\n",
    "test2 = \"\"\"\n",
    "365,\"```\\n{\\n  \"\"@openzeppelin/contracts\"\": \"\"4.3.1\"\",\\n  \"\"@openzeppelin/test-helpers\"\": \"\"0.5.6\"\",\\n  \"\"@openzeppelin/contracts-upgradeable\"\": \"\"4.3.1\"\"\\n}\\n```\",\"The UUPSUpgradeable vulnerability is a critical severity bug discovered in OpenZeppelin's contracts, specifically in versions 4.1.0 to 4.3.1. The affected contracts include `@openzeppelin/contracts` and `@openzeppelin/contracts-upgradeable`, which are widely used in the kyber-swap contracts, as evident from the `package.json` file.\\n\\nThe vulnerability allows an attacker to manipulate the upgrade process of UUPSUpgradeable contracts, enabling them to execute arbitrary code during the upgrade process. This can lead to unauthorized changes to the contract's behavior, potentially resulting in the theft of funds or unauthorized access to sensitive data.\\n\\nThe affected contracts, `PoolOracle.sol` and `TokenPositionDescriptor.sol`, are both UUPSUpgradeable and require immediate attention to ensure the security of the kyber-swap contracts. It is essential to upgrade these contracts to a fixed version, specifically `@openzeppelin/contracts` version 4.3.2 or higher, and `@openzeppelin/contracts-upgradeable` version 4.3.2 or higher, to mitigate this vulnerability.\",\"To mitigate the UUPSUpgradeable vulnerability in OpenZeppelin Contracts, follow these steps:nn1. **Update the OpenZeppelin library to the latest version**: Ensure that you are using the latest version of the OpenZeppelin Contracts library, which is version 4.3.2 or higher. This will ensure that you have the fix for the UUPSUpgradeable vulnerability.nn2. **Verify the UUPS implementation contracts**: Review the OpenZeppelin UUPS documentation to understand the correct implementation of UUPSUpgradeable contracts. This will help you identify any potential issues and ensure that your contracts are properly configured.nn3. **Check the affected contracts**: Identify the contracts that are affected by the UUPSUpgradeable vulnerability, such as PoolOracle.sol and TokenPositionDescriptor.sol. Review the code and ensure that they are using the latest version of the OpenZeppelin Contracts library.nn4. **Implement the UUPSUpgradeable contracts correctly**: Follow the OpenZeppelin UUPS documentation to implement the UUPSUpgradeable contracts correctly. This includes setting the `UUPSUpgradeable` contract as the base contract for your upgradeable contracts.nn5. **Test the UUPSUpgradeable contracts**: Thoroughly test the UUPSUpgradeable contracts to ensure that they are functioning correctly and that the upgrade process is working as expected.nn6. **Monitor the UUPSUpgradeable contracts**: Continuously monitor the UUPSUpgradeable contracts to ensure that they are not vulnerable to any new attacks or exploits.nnBy following these steps, you can effectively mitigate the UUPSUpgradeable vulnerability in OpenZeppelin Contracts and ensure the security of your smart contracts.\",upgradeable contract vulnerability\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(test1.replace('\\\\n', '\\n'))\n",
    "print(test2.replace('\\\\n', '\\n'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
